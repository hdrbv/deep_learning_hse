{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –î–æ–º–∞—à–Ω—è—è —Ä–∞–±–æ—Ç–∞ ‚Ññ1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disclaimer**: \n",
    "\n",
    "–î–ª—è –∫–∞–∂–¥–æ–π –¥–æ–º–∞—à–Ω–µ–π —Ä–∞–±–æ—Ç—ã –æ–±–æ–∑–Ω–∞—á–∞—é—Ç—Å—è –º—è–≥–∫–∏–µ –∏ –∂–µ—Å—Ç–∫–∏–µ –¥–µ–¥–ª–∞–π–Ω—ã. –ó–∞ –∫–∞–∂–¥—ã–π –¥–µ–Ω—å –ø—Ä–æ—Å—Ä–æ—á–∫–∏ –ø–æ—Å–ª–µ –º—è–≥–∫–æ–≥–æ –¥–µ–¥–ª–∞–π–Ω–∞ —Å–Ω–∏–º–∞–µ—Ç—Å—è 20% –æ—Ç –æ—Ü–µ–Ω–∫–∏.\n",
    "\n",
    "–ü–æ—Å–ª–µ –∂—ë—Å—Ç–∫–æ–≥–æ –¥–µ–¥–ª–∞–π–Ω–∞ —Ä–∞–±–æ—Ç—ã –Ω–µ –ø—Ä–∏–Ω–∏–º–∞—é—Ç—Å—è. –î–∞–∂–µ –ø—Ä–∏ –æ–ø–æ–∑–¥–∞–Ω–∏–∏ –Ω–∞ –æ–¥–Ω—É —Å–µ–∫—É–Ω–¥—É. –°–¥–∞–≤–∞–π—Ç–µ –∑–∞—Ä–∞–Ω–µ–µ.\n",
    "\n",
    "C—Ç—É–¥–µ–Ω—Ç –º–æ–∂–µ—Ç 1 —Ä–∞–∑ —Å–¥–∞—Ç—å –¥–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ –ø–æ—Å–ª–µ –º—è–≥–∫–æ–≥–æ –¥–µ–¥–ª–∞–π–Ω–∞ (–Ω–æ –¥–æ –∂—ë—Å—Ç–∫–æ–≥–æ) –±–µ–∑ —à—Ç—Ä–∞—Ñ–æ–≤.\n",
    "\n",
    "–í —Å–ª—É—á–∞–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (large language models (LLMs), –∫ –ø—Ä–∏–º–µ—Ä—É: ChatGPT, GigaChat, Qwen, etc):\n",
    "- –í chunk (—è—á–µ–π–∫—É) –≤—ã—à–µ –∫–æ–¥–∞, —Å–æ–∑–¥–∞–Ω–Ω–æ–≥–æ LLM, –ø—Ä–∏–∫—Ä–µ–ø–ª—è–π—Ç–µ –ø—Ä–æ–º–ø—Ç, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª—Å—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.\n",
    "- –û—Ç–¥–µ–ª—å–Ω–æ –æ–ø–∏—à–∏—Ç–µ –∫–∞–∫ –ø–æ–¥–±–∏—Ä–∞–ª–∏ –ø—Ä–æ–º–ø—Ç—ã, –∫–∞–∫–∏–µ –∑–∞–º–µ—Ç–∏–ª–∏ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–∏ GenAI –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è.\n",
    "- –ó–∞ —Ä–µ—à–µ–Ω–∏–µ —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º - _—à—Ç—Ä–∞—Ñ 40%_ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–µ—Ä–µ—Å–º–æ—Ç—Ä–µ–Ω –≤ —Å—Ç–æ—Ä–æ–Ω—É —É–≤–µ–ª–∏—á–µ–Ω–∏—è –≤ —Å–ª–µ–¥—É—é—â–∏—Ö —Å–ª—É—á–∞—è—Ö: \n",
    "    - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –æ—Ç–≤–µ—Ç LLM –±–µ–∑ —É–∫–∞–∑–∞–Ω–∏—è –ø—Ä–æ–º–ø—Ç–∞ _(—à—Ç—Ä–∞—Ñ 100%)_\n",
    "    - —Ä–µ—à–µ–Ω–∏–µ –∏–∑–±—ã—Ç–æ—á–Ω–æ –∏, –∏–ª–∏ –Ω–∞–ø–∏—Å–∞–Ω–æ –Ω–µ–æ–ø—Ç–∏–º–∞–ª—å–Ω–æ (–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ magic –∫–æ–º–∞–Ω–¥ –±–µ–∑ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ü–∏–∫–ª–æ–≤ –≤ —Ç–µ—Ö —Å–ª—É—á–∞—è—Ö, –∫–æ–≥–¥–∞ –æ–ø–µ—Ä–∞—Ü–∏—é –º–æ–∂–Ω–æ —Å–æ–≤–µ—Ä—à–∏—Ç—å –ø—Ä–∏ –ø–æ–º–æ—â–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –±–∏–±–ª–∏–æ—Ç–µ–∫, etc) _(—à—Ç—Ä–∞—Ñ 50%)_\n",
    "\n",
    "–¢–∞–∫–∂–µ: \n",
    "- –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª—é–±—ã–µ —Å–≤–æ–±–æ–¥–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ —Å *–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–º* —É–∫–∞–∑–∞–Ω–∏–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ –Ω–∏—Ö.\n",
    "- –ü–ª–∞–≥–∏–∞—Ç –Ω–µ –¥–æ–ø—É—Å–∫–∞–µ—Ç—Å—è. –ü—Ä–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–∏ —Å–ª—É—á–∞–µ–≤ —Å–ø–∏—Å—ã–≤–∞–Ω–∏—è, 0 –∑–∞ —Ä–∞–±–æ—Ç—É –≤—ã—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è –≤—Å–µ–º —É—á–∞—Å—Ç–Ω–∏–∫–∞–º –Ω–∞—Ä—É—à–µ–Ω–∏—è, –¥–∞–∂–µ –µ—Å–ª–∏ –º–æ–∂–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å, –∫—Ç–æ —É –∫–æ–≥–æ —Å–ø–∏—Å–∞–ª.\n",
    "- –ú—ã –≤ –ª—é–±–æ–º —Å–ª—É—á–∞–µ –æ—Å—Ç–∞–≤–ª—è–µ–º –∑–∞ —Å–æ–±–æ–π –ø—Ä–∞–≤–æ –ø—Ä–∏–≥–ª–∞—Å–∏—Ç—å —Å—Ç—É–¥–µ–Ω—Ç–∞ –¥–ª—è –∑–∞—â–∏—Ç—ã —Å–≤–æ–µ–≥–æ –î–ó, –µ—Å–ª–∏ –∑–∞–ø–æ–¥–æ–∑—Ä–∏–º –ø–ª–∞–≥–∏–∞—Ç."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQl6BxbTv-eK"
   },
   "source": [
    "# Activations\n",
    "\n",
    "–í —ç—Ç–æ–º —Ä–∞–∑–¥–µ–ª–µ –Ω–∞–ø–∏—à–µ–º —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—É—é —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é —Ñ—É–Ω–∫—Ü–∏–π –∞–∫—Ç–∏–≤–∞—Ü–∏–∏\n",
    "\n",
    "\n",
    "–ó–∞–ø—Ä–µ—â–µ–Ω–æ –≤–Ω—É—Ç—Ä–∏ —Å–≤–æ–µ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–æ–∑–¥–∞–≤–∞—Ç—å –∫–ª–∞—Å—Å –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –∏–∑ pytorch –∏ –ø—Ä–æ—Å—Ç–æ –ø—Ä–∏–º–µ–Ω—è—Ç—å –µ–≥–æ. –†–∞–∑—Ä–µ—à–µ–Ω–æ –∏—Å–ø–æ–ª–∑–æ–≤–∞—Ç—å –ø—Ä–æ—Å—Ç—ã–µ —Ñ-–∏–∏ pytorch —Ç–∏–ø–∞ [torch.exp](https://pytorch.org/docs/stable/generated/torch.exp.html) –∏ —Ç –¥\n",
    "\n",
    "–ï—Å–ª–∏ —É —Ñ-–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –µ—Å—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã, –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ç–∞–∫–æ–µ –∂–µ –∫–∞–∫ –≤ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ PyTorch\n",
    "\n",
    "**–ú–∞—Ç–µ—Ä–∏–∞–ª—ã –ø–æ pytorch:**\n",
    "\n",
    "* [PyTorch docs](https://pytorch.org/docs/stable/index.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bNMlqoCiv-eM"
   },
   "source": [
    "## Prerequirements\n",
    "\n",
    "```\n",
    "pip install torch numpy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uR_-L-78De7T"
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/60658965/7286121\n",
    "\n",
    "from IPython.core.magic import register_cell_magic\n",
    "\n",
    "@register_cell_magic\n",
    "def write_and_run(line, cell):\n",
    "    argz = line.split()\n",
    "    file = argz[-1]\n",
    "    mode = 'w'\n",
    "    if len(argz) == 2 and argz[0] == '-a':\n",
    "        mode = 'a'\n",
    "    with open(file, mode) as f:\n",
    "        f.write(cell)\n",
    "    get_ipython().run_cell(cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-24T12:02:03.697132Z",
     "iopub.status.busy": "2021-01-24T12:02:03.696647Z",
     "iopub.status.idle": "2021-01-24T12:02:05.150001Z",
     "shell.execute_reply": "2021-01-24T12:02:05.148949Z",
     "shell.execute_reply.started": "2021-01-24T12:02:03.697089Z"
    },
    "id": "ovtEtMOxv-eN"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qGTRWWFo5pOy"
   },
   "source": [
    "## –ó–∞–¥–∞–Ω–∏–µ 1\n",
    "–ù–∞–ø–∏—à–∏—Ç–µ —Å–≤–æ—é –≤–µ—Ä—Å–∏—é –≤–µ—Ä—Å–∏—é —Ñ—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ [ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9rZXbfck6WPO"
   },
   "outputs": [],
   "source": [
    "%%write_and_run myrelu.py \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyReLU(nn.Module):\n",
    "    \n",
    "    def forward(self, input):\n",
    "        # hint! –í—Ö–æ–¥–Ω–æ–π —Ç–µ–Ω–∑–æ—Ä –Ω—É–∂–Ω–æ —Å–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å,\n",
    "        # —á—Ç–æ–±—ã –¥–µ–π—Å—Ç–≤–∏—è–º–∏ –≤–Ω—É—Ç—Ä–∏ —ç—Ç–æ–≥–æ –º–µ—Ç–æ–¥–∞ –Ω–µ –ø—Ä–∏–≤–µ–ª–∏ –∫ –∏–∑–º–µ–Ω–µ–Ω–∏—é –≤–Ω–µ—à–Ω–µ–≥–æ –∞—Ä–≥—É–º–µ–Ω—Ç–∞\n",
    "        input_clone = torch.clone(input)\n",
    "        # ...\n",
    "        # return ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cRV-Ea2N5zDb"
   },
   "source": [
    "## –ó–∞–¥–∞–Ω–∏–µ 2\n",
    "–ù–∞–ø–∏—à–∏—Ç–µ —Å–≤–æ—é –≤–µ—Ä—Å–∏—é –≤–µ—Ä—Å–∏—é —Ñ—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ [LeakyReLU](https://pytorch.org/docs/stable/generated/torch.nn.LeakyReLU.html#torch.nn.LeakyReLU)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ouIrrlq63uN"
   },
   "outputs": [],
   "source": [
    "%%write_and_run myleakyrelu.py \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyLeakyReLU(nn.Module):\n",
    "    \n",
    "    def forward(self, input):\n",
    "        # hint! –í—Ö–æ–¥–Ω–æ–π —Ç–µ–Ω–∑–æ—Ä –Ω—É–∂–Ω–æ —Å–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å,\n",
    "        # —á—Ç–æ–±—ã –¥–µ–π—Å—Ç–≤–∏—è–º–∏ –≤–Ω—É—Ç—Ä–∏ —ç—Ç–æ–≥–æ –º–µ—Ç–æ–¥–∞ –Ω–µ –ø—Ä–∏–≤–µ–ª–∏ –∫ –∏–∑–º–µ–Ω–µ–Ω–∏—é –≤–Ω–µ—à–Ω–µ–≥–æ –∞—Ä–≥—É–º–µ–Ω—Ç–∞\n",
    "        input_clone = torch.clone(input)\n",
    "        # ...\n",
    "        # return ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YS2RXTz_55iS"
   },
   "source": [
    "## –ó–∞–¥–∞–Ω–∏–µ 3\n",
    "–ù–∞–ø–∏—à–∏—Ç–µ —Å–≤–æ—é –≤–µ—Ä—Å–∏—é –≤–µ—Ä—Å–∏—é —Ñ—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ [Sigmoid](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html#torch.nn.Sigmoid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QTHnuZQA67ga"
   },
   "outputs": [],
   "source": [
    "%%write_and_run mysigmoid.py \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MySigmoid(nn.Module):\n",
    "    \n",
    "    def forward(self, input):\n",
    "        # –¥–ª—è —ç—Ç–æ–≥–æ –∫–ª–∞—Å—Å–∞ –∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –≤—Ö–æ–¥–Ω–æ–π —Ç–µ–Ω–∑–æ—Ä —É–∂–µ –Ω–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏, –ø–æ—á–µ–º—É?\n",
    "        # ...\n",
    "        # return ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MGZs035Rv-eS"
   },
   "source": [
    "## –ó–∞–¥–∞–Ω–∏–µ 4\n",
    "–ù–∞–ø–∏—à–∏—Ç–µ —Å–≤–æ—é –≤–µ—Ä—Å–∏—é –≤–µ—Ä—Å–∏—é —Ñ—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ [ELU](https://pytorch.org/docs/stable/generated/torch.nn.ELU.html#torch.nn.ELU)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CT1IEmzFv-eT"
   },
   "outputs": [],
   "source": [
    "%%write_and_run myelu.py \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyELU(nn.Module):\n",
    "    \n",
    "    def forward(self, input):\n",
    "        # –¥–ª—è —ç—Ç–æ–≥–æ –∫–ª–∞—Å—Å–∞ –∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –≤—Ö–æ–¥–Ω–æ–π —Ç–µ–Ω–∑–æ—Ä —É–∂–µ –Ω–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏, –ø–æ—á–µ–º—É?\n",
    "        # ...\n",
    "        # return ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUfu8arDKoNm"
   },
   "source": [
    "## –¢–µ—Å—Ç\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uAagGpwSKqBN"
   },
   "outputs": [],
   "source": [
    "import pytest\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def _check_pytorch_module_was_not_used(file, module):\n",
    "\n",
    "    file = open(file, mode='r')\n",
    "    \n",
    "    assert module not in file.read(), \"pytorch module must not be used in you activation implementation\"\n",
    "    \n",
    "    file.close()\n",
    "\n",
    "    return\n",
    "\n",
    "def _test_activation(myactivation, torch_activation):\n",
    "    print(myactivation)\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        randinput = torch.rand([100])\n",
    "        myactivation_output = myactivation(randinput)\n",
    "\n",
    "        assert id(myactivation_output) != id(randinput), 'pytorch activation function must return new tensor'\n",
    "\n",
    "        for _ in range(100):\n",
    "            randinput = torch.rand([5, 5, 5])\n",
    "\n",
    "            assert torch.allclose(myactivation(randinput), torch_activation(randinput)), 'activation output is not equals to touch ones output'\n",
    "\n",
    "def test_relu():\n",
    "    from myrelu import MyReLU\n",
    "\n",
    "    my_activation = MyReLU()\n",
    "    \n",
    "    _check_pytorch_module_was_not_used(\"myrelu.py\", '.ReLU(')\n",
    "    _test_activation(my_activation, nn.ReLU())\n",
    "\n",
    "def test_leaky_relu():\n",
    "    from myleakyrelu import MyLeakyReLU\n",
    "\n",
    "    my_activation = MyLeakyReLU()\n",
    "    \n",
    "    _check_pytorch_module_was_not_used(\"myleakyrelu.py\", '.LeakyReLU(')\n",
    "    _test_activation(my_activation, nn.LeakyReLU())\n",
    "\n",
    "def test_sigmoid():\n",
    "    from mysigmoid import MySigmoid\n",
    "\n",
    "    my_activation = MySigmoid()\n",
    "    \n",
    "    _check_pytorch_module_was_not_used(\"mysigmoid.py\", '.MySigmoid(')\n",
    "    _test_activation(my_activation, nn.Sigmoid())\n",
    "\n",
    "def test_elu():\n",
    "    from myelu import MyELU\n",
    "\n",
    "    my_activation = MyELU()\n",
    "    \n",
    "    _check_pytorch_module_was_not_used(\"myelu.py\", '.MyELU(')\n",
    "    _test_activation(my_activation, nn.ELU())\n",
    "\n",
    "\n",
    "test_relu()\n",
    "test_leaky_relu()\n",
    "test_sigmoid()\n",
    "test_elu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpO0-LSGIac0"
   },
   "source": [
    "# Weight Initialization\n",
    "–í —ç—Ç–æ–º –Ω–æ—É—Ç–±—É–∫–µ –≤—ã —É–∑–Ω–∞–µ—Ç–µ, –∫–∞–∫ –Ω–∞–π—Ç–∏ —Ö–æ—Ä–æ—à–∏–µ –Ω–∞—á–∞–ª—å–Ω—ã–µ –≤–µ—Å–∞ –¥–ª—è –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏. \n",
    "–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –æ–¥–∏–Ω —Ä–∞–∑, –∫–æ–≥–¥–∞ –º–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞, –¥–æ –æ–±—É—á–µ–Ω–∏—è.\n",
    "–ò–º–µ—è —Ö–æ—Ä–æ—à–∏–µ –Ω–∞—á–∞–ª—å–Ω—ã–µ –≤–µ—Å–∞, –º–æ–∂–Ω–æ —Ä–∞—Å–ø–æ–ª–æ–∂–∏—Ç—å –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å –±–ª–∏–∑–∫–æ –∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–º—É —Ä–µ—à–µ–Ω–∏—é.\n",
    "–≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ –±—ã—Å—Ç—Ä–µ–µ —Å–æ–π—Ç–∏—Å—å –∫ –Ω–∞–∏–ª—É—á—à–µ–º—É —Ä–µ—à–µ–Ω–∏—é.\n",
    "\n",
    "\n",
    "## Initial Weights and Observing Training Loss\n",
    "\n",
    "–ß—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å, –∫–∞–∫ —Ä–∞–±–æ—Ç–∞—é—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–µ—Å–∞, –º—ã –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–µ–º –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∏ –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å. –¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –º—ã –∑–Ω–∞–µ–º, —á—Ç–æ –ª—é–±—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –ø–æ–≤–µ–¥–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏ –ø—Ä–æ–∏—Å—Ö–æ–¥—è—Ç –∏–∑-–∑–∞ –≤–µ—Å–æ–≤, –∞ –Ω–µ –∏–∑-–∑–∞ –∫–∞–∫–∏—Ö-–ª–∏–±–æ –∏–∑–º–µ–Ω–µ–Ω–∏–π –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏. \n",
    "\n",
    "### Dataset and Model\n",
    "\n",
    "–î–ª—è –∏–∑—É—á–µ–Ω–∏—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–π –º—ã –æ–±—É—á–∏–º MLP –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö [Fashion-MNIST] (https://github.com/zalandoresearch/fashion-mnist). –ù–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö FashionMNIST —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ç–∏–ø–æ–≤ –æ–¥–µ–∂–¥—ã; ' classes = ['—Ñ—É—Ç–±–æ–ª–∫–∞ / —Ç–æ–ø', '–±—Ä—é–∫–∏', '–ø—É–ª–æ–≤–µ—Ä', '–ø–ª–∞—Ç—å–µ', '–ø–∞–ª—å—Ç–æ', '—Å–∞–Ω–¥–∞–ª–∏–∏', '—Ä—É–±–∞—à–∫–∞', '–∫—Ä–æ—Å—Å–æ–≤–∫–∏', '—Å—É–º–∫–∞',`–±–æ—Ç–∏–ª—å–æ–Ω—ã']'. –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–æ—Ä–º–∞–ª–∏–∑—É—é—Ç—Å—è —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, —á—Ç–æ–±—ã –∏—Ö –ø–∏–∫—Å–µ–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞—Ö–æ–¥–∏–ª–∏—Å—å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ [0.0 - 1.0).  –ó–∞–ø—É—Å—Ç–∏—Ç–µ —è—á–µ–π–∫—É –Ω–∏–∂–µ, —á—Ç–æ–±—ã –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Pl7r9RDIac1"
   },
   "source": [
    "### Import Libraries and Load [Data](http://pytorch.org/docs/stable/torchvision/datasets.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8xNOEfk7Iac2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 100\n",
    "# percentage of training set to use as validation\n",
    "valid_size = 0.2\n",
    "\n",
    "# convert data to torch.FloatTensor\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# choose the training and test datasets\n",
    "train_data = datasets.FashionMNIST(root='data', train=True,\n",
    "                                   download=True, transform=transform)\n",
    "test_data = datasets.FashionMNIST(root='data', train=False,\n",
    "                                  download=True, transform=transform)\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define samplers for obtaining training and validation batches\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "# prepare data loaders (combine dataset and sampler)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "    sampler=train_sampler, num_workers=num_workers)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
    "    sampler=valid_sampler, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "    num_workers=num_workers)\n",
    "\n",
    "# specify the image classes\n",
    "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VtSyj5oPIadP"
   },
   "source": [
    "### Visualize Some Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G4_Xhj00IadP"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "    \n",
    "# obtain one batch of training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.numpy()\n",
    "\n",
    "# plot the images in the batch, along with the corresponding labels\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, int(20/2), idx+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
    "    ax.set_title(classes[labels[idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-A_HQmOHIadV"
   },
   "source": [
    "## –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏\n",
    "\n",
    "–ú—ã —Å–æ–∑–¥–∞–¥–∏–º MLP (multilayer perceptron), –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö, —Å–æ —Å–ª–µ–¥—É—é—â–∏–º–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏:\n",
    "\n",
    "\n",
    "* 3 –ª–∏–Ω–µ–π–Ω—ã—Ö —Å–ª–æ—è —Å —Ä–∞–∑–º–µ—Ä–∞–º–∏ 256 –∏ 128; \n",
    "\n",
    "* MLP –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –≤ –∫–∞—á–µ—Å—Ç–≤–µ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤—ã–ø—Ä—è–º–ª–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (–≤–µ–∫—Ç–æ—Ä –¥–ª–∏–Ω—ã 784) –∏ –≤—ã–¥–∞–µ—Ç –æ—Ü–µ–Ω–∫—É –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç–∏ –æ–±—ä–µ–∫—Ç–∞ –∫ –∫–∞–∂–¥–æ–º—É –∏–∑ 10 –∫–ª–∞—Å—Å–æ–≤.\n",
    "---\n",
    "–ú—ã –ø—Ä–æ–≤–µ—Ä–∏–º –≤–ª–∏—è–Ω–∏–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–π –Ω–∞ —ç—Ç—É 3-—Å–ª–æ–π–Ω—É—é –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å, –æ–±—É—á–µ–Ω–Ω—É—é —Å –∞–∫—Ç–∏–≤–∞—Ü–∏—è–º–∏ ReLU –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–æ–º Adam.  \n",
    "\n",
    "–ü–æ–ª—É—á–µ–Ω–Ω—ã–µ –≤—ã–≤–æ–¥—ã –ø—Ä–∏–º–µ–Ω–∏–º—ã –∏ –∫ –¥—Ä—É–≥–∏–º –Ω–µ–π—Ä–æ–Ω–Ω—ã–º —Å–µ—Ç—è–º, –≤–∫–ª—é—á–∞—è —Ä–∞–∑–ª–∏—á–Ω—ã–µ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GVgjRR_QIadW"
   },
   "source": [
    "---\n",
    "\n",
    "### All Zeros or Ones\n",
    "–°–ª–µ–¥—É—è –ø—Ä–∏–Ω—Ü–∏–ø–∞–º –±—Ä–∏—Ç–≤—ã –û–∫–∫–∞–º–∞ ([Occam's razor](https://en.wikipedia.org/wiki/Occam's_razor)), –≤—ã –º–æ–≥–ª–∏ –±—ã –µ—Å—Ç–µ—Å—Ç–µ–≤–µ–Ω–Ω–æ –ø–æ–¥—É–º–∞—Ç—å, —á—Ç–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–æ–∏–Ω–∏—Ü–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ –≤–µ—Å–∞ –Ω—É–ª–µ–º –∏–ª–∏ –µ–¥–∏–Ω–∏—Ü–µ–π.\n",
    "\n",
    "–ü—Ä–∏ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–º –≤–µ—Å–µ –≤—Å–µ –Ω–µ–π—Ä–æ–Ω—ã –≤ –∫–∞–∂–¥–æ–º —Å–ª–æ–µ –≤—ã–¥–∞—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç.  –≠—Ç–æ –∑–∞—Ç—Ä—É–¥–Ω—è–µ—Ç –æ–±—É—á–µ–Ω–∏–µ, —Ç–∞–∫ –∫–∞–∫ –Ω–µ–ø–æ–Ω—è—Ç–Ω–æ, –∫–∞–∫–∏–µ –∏–º–µ–Ω–Ω–æ –≤–µ—Å–∞ –≤ –∫–∞–∫—É—é —Å—Ç–æ—Ä–æ–Ω—É –Ω—É–∂–Ω–æ –º–µ–Ω—è—Ç—å.\n",
    "\n",
    "–î–∞–≤–∞–π—Ç–µ —Å—Ä–∞–≤–Ω–∏–º —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –¥–ª—è –¥–≤—É—Ö –º–æ–¥–µ–ª–µ–π, –ø—Ä–æ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö (1) –Ω—É–ª—è–º–∏ –∏ (2) –µ–¥–∏–Ω–∏—Ü–∞–º–∏.\n",
    "\n",
    "–ù–∏–∂–µ –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º Pytorch's [nn. init](https://pytorch.org/docs/stable/nn.html#torch-nn-init), —á—Ç–æ–±—ã –ø—Ä–æ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–µ—Å–∞ –∫–∞–∂–¥–æ–≥–æ –ª–∏–Ω–µ–π–Ω–æ–≥–æ —Å–ª–æ—è –∫–æ–Ω—Å—Ç–∞–Ω—Ç–Ω–æ–π. –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ init –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ä—è–¥ —Ñ—É–Ω–∫—Ü–∏–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –¥–∞—é—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–µ—Å–∞ –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ—è –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –µ–≥–æ —Ç–∏–ø–æ–º.\n",
    "–î–ª—è –ª–∏–Ω–µ–π–Ω–æ–≥–æ —Å–ª–æ—è –≤–µ—Å–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Ç—Å—è —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º:\n",
    "\n",
    ">```\n",
    "if isinstance(m, nn.Linear):\n",
    "    nn.init.constant_(m.weight, constant_weight)\n",
    "    nn.init.constant_(m.bias, 0)\n",
    "```\n",
    "\n",
    "–≥–¥–µ `constant_weight` - –∑–Ω–∞—á–µ–Ω–∏–µ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã (–≤ –Ω–∞—à–µ–º —Å–ª—É—á–∞–µ 0 –∏–ª–∏ 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWNwHkLuti_Q"
   },
   "source": [
    "**–ó–∞–¥–∞–Ω–∏–µ**: –æ–ø—Ä–µ–¥–µ–ª–∏—Ç–µ –º–æ–¥–µ–ª—å c –æ–ø–∏—Å–∞–Ω–Ω–æ–π –≤—ã—à–µ –∞—Ä—Ö–∏—Ç—É–∫—Ç—É—Ä–æ–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4JLlJa8FIadZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the NN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, hidden_1=256, hidden_2=128, constant_weight=None):\n",
    "        super(Net, self).__init__()\n",
    "        # linear layer (784 -> hidden_1)\n",
    "        self.fc1 = \n",
    "        # linear layer (hidden_1 -> hidden_2)\n",
    "        self.fc2 = \n",
    "        # linear layer (hidden_2 -> 10)\n",
    "        self.fc3 =\n",
    "        # dropout layer (p=0.2)\n",
    "        self.dropout =\n",
    "        \n",
    "        # initialize the weights to a specified, constant value\n",
    "        if(constant_weight is not None):\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Linear):\n",
    "                    nn.init.constant_(m.weight, constant_weight)\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "            \n",
    "    def forward(self, x):\n",
    "        # flatten image input\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        # add hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # add hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # add output layer\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_IaEhz74Iadg"
   },
   "source": [
    "### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ–≤–µ–¥–µ–Ω–∏—è –º–æ–¥–µ–ª–∏\n",
    "\n",
    "–ù–∏–∂–µ –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é `.compare_init_weights`, —á—Ç–æ–±—ã —Å—Ä–∞–≤–Ω–∏—Ç—å —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏ –∏ —Ç–µ—Å—Ç–µ –¥–ª—è –¥–≤—É—Ö –º–æ–¥–µ–ª–µ–π: `model_0` –∏ `model_1`.  –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π (–∫–∞–∂–¥–∞—è —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –Ω–∞—á–∞–ª—å–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏), –Ω–∞–∑–≤–∞–Ω–∏–µ —Å–æ–∑–¥–∞–≤–∞–µ–º–æ–≥–æ –≥—Ä–∞—Ñ–∏–∫–∞, –∞ —Ç–∞–∫–∂–µ –∑–∞–≥—Ä—É–∑—á–∏–∫–∏ –æ–±—É—á–∞—é—â–∏—Ö –∏ —Ç–µ—Å—Ç–æ–≤—ã—Ö –Ω–∞–±–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö. –î–ª—è –∫–∞–∂–¥–æ–π –∑–∞–¥–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ —ç—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—é –ø–æ—Å—Ç—Ä–æ–∏—Ç –≥—Ä–∞—Ñ–∏–∫ –ª–æ—Å—Å–∞ –≥–∞ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –ø–µ—Ä–≤—ã—Ö 100 –±–∞—Ç—á–µ–π –∏ –≤—ã–≤–µ–¥–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø–æ—Å–ª–µ 2 —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è. \n",
    "\n",
    "*–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –ï—Å–ª–∏ –≤—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ –±–∞—Ç—á–∏ –º–µ–Ω—å—à–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞, –≤—ã –º–æ–∂–µ—Ç–µ —É–≤–µ–ª–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –∑–¥–µ—Å—å, —á—Ç–æ–±—ã –ª—É—á—à–µ —Å—Ä–∞–≤–Ω–∏—Ç—å, –∫–∞–∫ –≤–µ–¥—É—Ç —Å–µ–±—è –º–æ–¥–µ–ª–∏ –ø–æ—Å–ª–µ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–æ—Ç–µ–Ω –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.* \n",
    "\n",
    "\n",
    "**–ó–∞–¥–∞–Ω–∏–µ**: –î–æ–ø–∏—à–∏—Ç–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ —è—á–µ–π–∫–∏ –Ω–∏–∂–µ, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å —Ä–∞–∑–Ω–∏—Ü—É –º–µ–∂–¥—É –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è–º–∏ –≤—Å–µ–º–∏ –Ω—É–ª—è–º–∏ –∏ –≤—Å–µ–º–∏ –µ–¥–∏–Ω–∏—Ü–∞–º–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MDxbliCuIadh"
   },
   "outputs": [],
   "source": [
    "# initialize two NN's with 0 and 1 constant weights\n",
    "model_0 = Net(constant_weight=0)\n",
    "model_1 = Net(constant_weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xrmqVW1MKWHT"
   },
   "outputs": [],
   "source": [
    "\n",
    "def _get_loss_acc(model, train_loader, valid_loader):\n",
    "    \"\"\"\n",
    "    Get losses and validation accuracy of example neural network\n",
    "    \"\"\"\n",
    "    n_epochs = 2\n",
    "    learning_rate = 0.001\n",
    "    \n",
    "    # Training loss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = optimizer = torch.optim.Adam(model.parameters(), learning_rate)\n",
    "\n",
    "    # Measurements used for graphing loss\n",
    "    loss_batch = []\n",
    "\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize var to monitor training loss\n",
    "        train_loss = 0.0\n",
    "        ########################\n",
    "        # TODO train the model #\n",
    "        ########################\n",
    "        for data, target in train_loader:\n",
    "            # clear the gradients of all optimized variables\n",
    "            \n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = \n",
    "            # calculate the batch loss\n",
    "            loss = \n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            # perform a single optimization step (parameter update)\n",
    "            # record average batch loss \n",
    "             \n",
    "    # after training for 2 epochs, check validation accuracy \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data, target in valid_loader:\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # get the predicted class from the maximum class score\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        # count up total number of correct labels\n",
    "        # for which the predicted and true labels are equal\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum()\n",
    "      \n",
    "    # calculate the accuracy\n",
    "    # to convert `correct` from a Tensor into a scalar, use .item()\n",
    "    valid_acc = correct.item() / total\n",
    "\n",
    "    # return model stats\n",
    "    return loss_batch, valid_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JKNMCYznIadn"
   },
   "outputs": [],
   "source": [
    "\n",
    "def compare_init_weights(\n",
    "        model_list,\n",
    "        plot_title,\n",
    "        train_loader,\n",
    "        valid_loader,\n",
    "        plot_n_batches=100):\n",
    "    \"\"\"\n",
    "    Plot loss and print stats of weights using an example neural network\n",
    "    \"\"\"\n",
    "    colors = ['r', 'b', 'g', 'c', 'y', 'k']\n",
    "    label_accs = []\n",
    "    label_loss = []\n",
    "\n",
    "    assert len(model_list) <= len(colors), 'Too many initial weights to plot'\n",
    "\n",
    "    for i, (model, label) in enumerate(model_list):\n",
    "        torch.save(model.state_dict(), f\"{label}.pt\")\n",
    "\n",
    "        loss, val_acc = _get_loss_acc(model, train_loader, valid_loader)\n",
    "\n",
    "        plt.plot(loss[:plot_n_batches], colors[i], label=label)\n",
    "        label_accs.append((label, val_acc))\n",
    "        label_loss.append((label, loss[-1]))\n",
    "\n",
    "    plt.title(plot_title)\n",
    "    plt.xlabel('Batches')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()\n",
    "\n",
    "    print('After 2 Epochs:')\n",
    "    print('Validation Accuracy')\n",
    "    for label, val_acc in label_accs:\n",
    "        print('  {:7.3f}% -- {}'.format(val_acc*100, label))\n",
    "    print('Training Loss')\n",
    "    for label, loss in label_loss:\n",
    "        print('  {:7.3f}  -- {}'.format(loss, label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C4H_ov6gKPC2"
   },
   "outputs": [],
   "source": [
    "model_list = [(model_0, 'All Zeros'),   # –Ω–µ –Ω–∞–¥–æ –º–µ–Ω—è—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ –ª–µ–π–±–ª–∞ –º–æ–¥–µ–ª–∏, –Ω–∞ —ç—Ç–æ –∑–∞–≤—è–∑–∞–Ω—ã —Ç–µ—Å—Ç—ã\n",
    "              (model_1, 'All Ones')]    # –Ω–µ –Ω–∞–¥–æ –º–µ–Ω—è—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ –ª–µ–π–±–ª–∞ –º–æ–¥–µ–ª–∏, –Ω–∞ —ç—Ç–æ –∑–∞–≤—è–∑–∞–Ω—ã —Ç–µ—Å—Ç—ã\n",
    "\n",
    "compare_init_weights(model_list, \n",
    "                             'All Zeros vs All Ones', \n",
    "                             train_loader,\n",
    "                             valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jMZF8HhhIadp"
   },
   "source": [
    "–ö–∞–∫ –≤—ã –º–æ–∂–µ—Ç–µ –≤–∏–¥–µ—Ç—å, —Ç–æ—á–Ω–æ—Å—Ç—å –±–ª–∏–∑–∫–∞ –∫ —Å–ª—É—á–∞–π–Ω–æ–º—É —É–≥–∞–¥—ã–≤–∞–Ω–∏—é –∫–∞–∫ –¥–ª—è –Ω—É–ª–µ–π, —Ç–∞–∫ –∏ –¥–ª—è –µ–¥–∏–Ω–∏—Ü, –æ–∫–æ–ª–æ 10%.\n",
    "\n",
    "–ù–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ —Ç—Ä—É–¥–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, –∫–∞–∫–∏–µ –≤–µ—Å–∞ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∏–∑–º–µ–Ω–µ–Ω—ã, —Ç–∞–∫ –∫–∞–∫ –Ω–µ–π—Ä–æ–Ω—ã –∏–º–µ—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π –≤—ã—Ö–æ–¥ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ—è.  –ß—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –Ω–µ–π—Ä–æ–Ω–æ–≤ —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º –≤—ã—Ö–æ–¥–æ–º, –¥–∞–≤–∞–π—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –≤–µ—Å–∞.  –ú—ã —Ç–∞–∫–∂–µ –º–æ–∂–µ–º —Å–ª—É—á–∞–π–Ω—ã–º –æ–±—Ä–∞–∑–æ–º –≤—ã–±—Ä–∞—Ç—å –≤–µ—Å–∞, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –∑–∞—Å—Ç—Ä–µ–≤–∞–Ω–∏—è –≤ –ª–æ–∫–∞–ª—å–Ω–æ–º –º–∏–Ω–∏–º—É–º–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—É—Å–∫–∞.\n",
    "\n",
    "–•–æ—Ä–æ—à–∏–º —Ä–µ—à–µ–Ω–∏–µ–º –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —ç—Ç–∏—Ö —Å–ª—É—á–∞–π–Ω—ã—Ö –≤–µ—Å–æ–≤ —è–≤–ª—è–µ—Ç—Å—è –≤—ã–±–æ—Ä–∫–∞ –∏–∑ –æ–¥–Ω–æ—Ä–æ–¥–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sQXCy-4LUq-"
   },
   "source": [
    "# –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "\n",
    "–î–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã –∑–∞–ø—É—Å–∫ –≤ –∫–æ–ª–∞–±–µ –∏ –∑–∞–ø—É—Å–∫ –≤ –ø–∞–π–ø–ª–∞–π–Ω—ã—Ö –±—ã–ª–∏ –±–æ–ª–µ–µ-–º–µ–Ω–µ–µ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º—ã, –≤–æ—Å–ø–æ–ª—å–∑—É–π—Ç–µ—Å—å —Å–ª–µ–¥—É—é—â–µ–π —Ñ—É–Ω–∫—Ü–∏–µ–π. –°–º —Ç–∞–∫ –∂–µ [–∑–∞–º–µ—Ç–∫—É](https://pytorch.org/docs/stable/notes/randomness.html) –æ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ –≤ –¥–æ–∫. pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vun0jePgLSou"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    import random, os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    if torch.__version__ >= '1.8':\n",
    "        torch.use_deterministic_algorithms()\n",
    "    else:\n",
    "        torch.set_deterministic(True)\n",
    "\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "aa4-lO_dIadq"
   },
   "source": [
    "### –†–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ\n",
    "[–†–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ](https://en.wikipedia.org/wiki/Uniform_distribution) –∏–º–µ–µ—Ç —Ä–∞–≤–Ω—É—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≤—ã–±–æ—Ä–∞ –ª—é–±–æ–≥–æ —á–∏—Å–ª–∞ –∏–∑ –Ω–∞–±–æ—Ä–∞. –ú—ã –±—É–¥–µ–º –≤—ã–±–∏—Ä–∞—Ç—å –∏–∑ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è, –ø–æ—ç—Ç–æ–º—É –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≤—ã–±–æ—Ä–∞ –æ–¥–Ω–æ–≥–æ –∏ —Ç–æ–≥–æ –∂–µ —á–∏—Å–ª–∞ –Ω–µ–≤–µ–ª–∏–∫–∞. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7B_gpGUMIadu"
   },
   "source": [
    "### Uniform Initialization, Baseline\n",
    "\n",
    "\n",
    "–î–∞–≤–∞–π—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–∏–º, –Ω–∞—Å–∫–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–æ –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å —Ç—Ä–µ–Ω–∏—Ä—É–µ—Ç—Å—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≤–µ—Å–æ–≤, –≥–¥–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è `a=0.0` –∏ `b=1.0`. –ú—ã —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º –¥—Ä—É–≥–æ–π —Å–ø–æ—Å–æ–± –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≤–µ—Å–æ–≤ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ (–ø–æ–º–∏–º–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –≤ –∫–æ–¥–µ –∫–ª–∞—Å—Å–∞ Net). –ß—Ç–æ–±—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–µ—Å–∞ –≤–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –º–æ–¥–µ–ª–∏, –≤—ã –º–æ–∂–µ—Ç–µ:\n",
    "1. –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤–µ—Å–∞ –Ω—É–∂–Ω—ã—Ö —Å–ª–æ–µ–≤ (–≤ –Ω–∞—à–µ–º —Å–ª—É—á–∞–µ - –ª–∏–Ω–µ–π–Ω—ã—Ö)\n",
    "\n",
    "2. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å, –∏—Å–ø–æ–ª—å–∑—É—è `model.apply(fn)`, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–∏–º–µ–Ω—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏—é `fn` –∫ –∫–∞–∂–¥–æ–º—É —Å–ª–æ—é –º–æ–¥–µ–ª–∏.\n",
    "\n",
    "–î–ª—è —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≤–µ—Å–æ–≤ –Ω–∞—à–µ–π –º–æ–¥–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `weight.data.uniform_`.\n",
    "\n",
    "**–ó–∞–¥–∞–Ω–∏–µ:** –¥–æ–ø–∏—à–∏—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≤–µ—Å–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2vgzzwcqIadv"
   },
   "outputs": [],
   "source": [
    "# takes in a module and applies the specified weight initialization\n",
    "def weights_init_uniform(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # for every Linear layer in a model.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0DvzLfUwIady"
   },
   "outputs": [],
   "source": [
    "# create a new model with these weights\n",
    "model_uniform = Net()\n",
    "\n",
    "seed_everything(42)\n",
    "model_uniform.apply(weights_init_uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cJ9tT12SIaeG"
   },
   "outputs": [],
   "source": [
    "# evaluate behavior \n",
    "compare_init_weights([(model_uniform, 'Uniform Weights')],  # –Ω–µ –Ω–∞–¥–æ –º–µ–Ω—è—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ –ª–µ–π–±–ª–∞ –º–æ–¥–µ–ª–∏, –Ω–∞ —ç—Ç–æ –∑–∞–≤—è–∑–∞–Ω—ã —Ç–µ—Å—Ç—ã\n",
    "                             'Uniform Baseline', \n",
    "                             train_loader,\n",
    "                             valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qdMazkSiIaeX"
   },
   "source": [
    "---\n",
    "–ì—Ä–∞—Ñ–∏–∫ –ø–æ—Ç–µ—Ä—å –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å —É—á–∏—Ç—Å—è, —á–µ–≥–æ –æ–Ω–∞ –Ω–µ –¥–µ–ª–∞–ª–∞ —Å–æ –≤—Å–µ–º–∏ –Ω—É–ª—è–º–∏ –∏–ª–∏ —Å–æ –≤—Å–µ–º–∏ –µ–¥–∏–Ω–∏—Ü–∞–º–∏. –ú—ã –¥–≤–∏–∂–µ–º—Å—è –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏!\n",
    "\n",
    "## –û–±—â–µ–µ –ø—Ä–∞–≤–∏–ª–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≤–µ—Å–æ–≤\n",
    "–û–±—â–µ–µ –ø—Ä–∞–≤–∏–ª–æ –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≤–µ—Å–æ–≤ –≤ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ —Å–æ—Å—Ç–æ–∏—Ç –≤ —Ç–æ–º, —á—Ç–æ–±—ã —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∏—Ö –±–ª–∏–∑–∫–∏–º–∏ –∫ –Ω—É–ª—é, –Ω–æ –Ω–µ —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–º–∏. \n",
    ">–•–æ—Ä–æ—à–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞ –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ —Ç–æ–º, —á—Ç–æ–±—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–µ—Å–∞ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ $[- y, y]$, –≥–¥–µ $y=1/\\sqrt{n}$  \n",
    "($n$ - —ç—Ç–æ —á–∏—Å–ª–æ –≤—Ö–æ–¥–æ–≤ –≤ –¥–∞–Ω–Ω—ã–π –Ω–µ–π—Ä–æ–Ω).\n",
    "\n",
    "–î–∞–≤–∞–π—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–∏–º, –≤–µ—Ä–Ω–æ –ª–∏ —ç—Ç–æ: —Ü–µ–Ω—Ç—Ä–∏—Ä—É–µ–º –Ω–∞—à —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –Ω—É–ª—è, —Å–¥–≤–∏–Ω—É–≤ –µ–≥–æ –Ω–∞ 0,5.  –≠—Ç–æ –¥–∞—Å—Ç –Ω–∞–º –¥–∏–∞–ø–∞–∑–æ–Ω [-0.5, 0.5] —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è.\n",
    "\n",
    "**–ó–∞–¥–∞–Ω–∏–µ:** –ø–æ–º–µ–Ω—è–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≤–µ—Å–æ–≤, —á—Ç–æ–±—ã —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤ –±—ã–ª–æ –≤ –¥–∏–∞–ø–æ–∑–æ–Ω–µ [-0.5, 0.5]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KxQzgLVrIaeZ"
   },
   "outputs": [],
   "source": [
    "# takes in a module and applies the specified weight initialization\n",
    "def weights_init_uniform_center(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # for every Linear layer in a model..\n",
    " \n",
    "# create a new model with these weights\n",
    "model_centered = Net()\n",
    "\n",
    "seed_everything(42)\n",
    "model_centered.apply(weights_init_uniform_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n88LC249Iaei"
   },
   "outputs": [],
   "source": [
    "# takes in a module and applies the specified weight initialization\n",
    "def weights_init_uniform_rule(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # for every Linear layer in a model..\n",
    "\n",
    "# create a new model with these weights\n",
    "model_rule = Net()\n",
    "model_rule.apply(weights_init_uniform_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dxc-99kCIaem"
   },
   "outputs": [],
   "source": [
    "model_list = [(model_centered, 'Centered Weights [-0.5, 0.5)'),  # –Ω–µ –Ω–∞–¥–æ –º–µ–Ω—è—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ –ª–µ–π–±–ª–∞ –º–æ–¥–µ–ª–∏, –Ω–∞ —ç—Ç–æ –∑–∞–≤—è–∑–∞–Ω—ã —Ç–µ—Å—Ç—ã\n",
    "              (model_rule, 'General Rule [-y, y)')]              # –Ω–µ –Ω–∞–¥–æ –º–µ–Ω—è—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ –ª–µ–π–±–ª–∞ –º–æ–¥–µ–ª–∏, –Ω–∞ —ç—Ç–æ –∑–∞–≤—è–∑–∞–Ω—ã —Ç–µ—Å—Ç—ã\n",
    "\n",
    "compare_init_weights(model_list, \n",
    "                             '[-0.5, 0.5) vs [-y, y)', \n",
    "                             train_loader,\n",
    "                             valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZZ_3YtuIaep"
   },
   "source": [
    "–¢–∞–∫–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –º–Ω–æ–≥–æ–æ–±–µ—â–∞—é—â–µ! –ú–∞–ª–æ —Ç–æ–≥–æ, —á—Ç–æ –ª–æ—Å—Å —É–º–µ–Ω—å—à–∞–µ—Ç—Å—è, –Ω–æ, –∫–∞–∂–µ—Ç—Å—è, —ç—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –æ—á–µ–Ω—å –±—ã—Å—Ç—Ä–æ; –≤—Å–µ–≥–æ —á–µ—Ä–µ–∑ –¥–≤–µ —ç–ø–æ—Ö–∏ –º—ã –ø–æ–ª—É—á–∞–µ–º –¥–æ–≤–æ–ª—å–Ω–æ –≤—ã—Å–æ–∫—É—é —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–µ. –≠—Ç–æ –¥–æ–ª–∂–Ω–æ –¥–∞—Ç—å –≤–∞–º –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –æ —Ç–æ–º, –ø–æ—á–µ–º—É —Ö–æ—Ä–æ—à–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –º–æ–∂–µ—Ç –ø–æ–º–æ—á—å —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–º—É –ø—Ä–æ—Ü–µ—Å—Å—É!\n",
    "\n",
    "---\n",
    "\n",
    "–†–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏–º–µ–µ—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π —à–∞–Ω—Å –≤—ã–±—Ä–∞—Ç—å *–ª—é–±–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ* –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ. –ß—Ç–æ, –µ—Å–ª–∏ –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ –∏–º–µ–µ—Ç –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–π —à–∞–Ω—Å –≤—ã–±—Ä–∞—Ç—å —á–∏—Å–ª–∞ –±–ª–∏–∂–µ –∫ 0?  –î–∞–≤–∞–π—Ç–µ —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ.\n",
    "\n",
    "### H–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ\n",
    "–í –æ—Ç–ª–∏—á–∏–µ –æ—Ç —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è, [–Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ](https://en.wikipedia.org/wiki/Normal_distribution) –∏–º–µ–µ—Ç –±–æ–ª–µ–µ –≤—ã—Å–æ–∫—É—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≤—ã–±–æ—Ä–∞ —á–∏—Å–ª–∞, –±–ª–∏–∑–∫–æ–≥–æ –∫ —Å—Ä–µ–¥–Ω–µ–º—É –∑–Ω–∞—á–µ–Ω–∏—é."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6KlG2T2Iaer"
   },
   "source": [
    "**–ó–∞–¥–∞–Ω–∏–µ:** –¥–æ–±–∞–≤—å—Ç–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ:\n",
    "–∫–∞–∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –≤—ã–±–µ—Ä–∏—Ç–µ $y=1/\\sqrt{n}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yWtr-z3WIaes"
   },
   "outputs": [],
   "source": [
    "## complete this function\n",
    "def weights_init_normal(m):\n",
    "    '''Takes in a module and initializes all linear layers with weight\n",
    "       values taken from a normal distribution.'''\n",
    "    \n",
    "    classname = m.__class__.__name__\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iriwx51SIaev"
   },
   "outputs": [],
   "source": [
    "## -- no need to change code below this line -- ##\n",
    "\n",
    "# create a new model with the rule-based, uniform weights\n",
    "model_uniform_rule = Net()\n",
    "\n",
    "seed_everything(42)\n",
    "model_uniform_rule.apply(weights_init_uniform_rule)\n",
    "\n",
    "# create a new model with the rule-based, NORMAL weights\n",
    "model_normal_rule = Net()\n",
    "\n",
    "seed_everything(42)\n",
    "model_normal_rule.apply(weights_init_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u52PY05QIaez"
   },
   "outputs": [],
   "source": [
    "model_list = [(model_uniform_rule, 'Uniform Rule [-y, y)'), # –Ω–µ –Ω–∞–¥–æ –º–µ–Ω—è—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ –ª–µ–π–±–ª–∞ –º–æ–¥–µ–ª–∏, –Ω–∞ —ç—Ç–æ –∑–∞–≤—è–∑–∞–Ω—ã —Ç–µ—Å—Ç—ã\n",
    "              (model_normal_rule, 'Normal Distribution')]   # –Ω–µ –Ω–∞–¥–æ –º–µ–Ω—è—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ –ª–µ–π–±–ª–∞ –º–æ–¥–µ–ª–∏, –Ω–∞ —ç—Ç–æ –∑–∞–≤—è–∑–∞–Ω—ã —Ç–µ—Å—Ç—ã\n",
    "\n",
    "compare_init_weights(model_list, \n",
    "                             'Uniform vs Normal', \n",
    "                             train_loader,\n",
    "                             valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhmqCw3ZIae2"
   },
   "source": [
    "–ù–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–∞–µ—Ç –Ω–∞–º –¥–æ–≤–æ–ª—å–Ω–æ –ø–æ—Ö–æ–∂–µ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω—ã–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –≤ –¥–∞–Ω–Ω–æ–º —Å–ª—É—á–∞–µ. –í–µ—Ä–æ—è—Ç–Ω–æ, —ç—Ç–æ —Å–≤—è–∑–∞–Ω–æ —Å —Ç–µ–º, —á—Ç–æ –Ω–∞—à–∞ —Å–µ—Ç—å –æ—á–µ–Ω—å –º–∞–ª–∞; –±–æ–ª–µ–µ –∫—Ä—É–ø–Ω–∞—è –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –±—É–¥–µ—Ç –≤—ã–±–∏—Ä–∞—Ç—å –±–æ–ª—å—à–µ –≤–µ—Å–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –∏–∑ –∫–∞–∂–¥–æ–≥–æ –∏–∑ —ç—Ç–∏—Ö —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π, —É–≤–µ–ª–∏—á–∏–≤–∞—è —ç—Ñ—Ñ–µ–∫—Ç –æ–±–æ–∏—Ö —Å—Ç–∏–ª–µ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏. –í –æ–±—â–µ–º —Å–ª—É—á–∞–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏–≤–µ–¥–µ—Ç –∫ —É–ª—É—á—à–µ–Ω–∏—é –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.01 –±–∞–ª–ª)** –í—Å—Ç–∞–≤—å—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –æ–ø–∏—Å—ã–≤–∞—é—â–µ–µ –≤–∞—Å –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω–æ–≥–æ –¥–æ–º–∞—à–Ω–µ–≥–æ –∑–∞–¥–∞–Ω–∏—è üòä"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media.tenor.com/ZCpXCL6vnDoAAAAC/minion-funny.gif\" style=\"width: 400px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
